{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** The model estimation code is intended to work with an experimental parallelised Vensim engine. With appropriate modifications to the main function calls (but not the analytical procedure), the same analysis can be run on regular commercially available Vensim DSS, though it will take *much* longer. Please contact [Tom Fiddaman](mailto:tom@ventanasystems.com) for information on the experimental Vensim engine.\n",
    "\n",
    "For more information on the model estimation procedure, see S1 of the Supplementary Materials of the paper.\n",
    "\n",
    "**Note:** if running in Jupyter, the `keyboard` module may need to be installed directly in the Notebook; see [here](https://stackoverflow.com/questions/38368318/installing-a-pip-package-from-within-a-jupyter-notebook-not-working) for example. The `keyboard` module is *only* used to bypass Vengine error messages; if not running Vengine (e.g. using normal Vensim DSS), it is not necessary, and you can safely remove the import statement and all `press` commands in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from keyboard import press\n",
    "from shutil import copy\n",
    "from distutils.dir_util import copy_tree\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "##### CLASS & FUNCTION DEFINITIONS FOR WORKING WITH VENSIM/VENGINE #####\n",
    "\n",
    "class Script(object):\n",
    "    \"\"\"Master object for holding and modifying .cmd script settings, \n",
    "    creating .cmd files, and running them through Vensim/Vengine\"\"\"\n",
    "    def __init__(self, controlfile):\n",
    "        print(\"Initialising\", self)\n",
    "        for k, v in controlfile['simsettings'].items():\n",
    "            self.__setattr__(k, v if isinstance(v, str) else v.copy())\n",
    "        self.setvals = []\n",
    "        self.runcmd = \"MENU>RUN_OPTIMIZE|o\\n\"\n",
    "        self.savecmd = f\"MENU>VDF2TAB|!|!|{self.savelist}|\\n\"\n",
    "        self.basename = controlfile['baserunname']\n",
    "        self.cmdtext = []\n",
    "        \n",
    "    def copy_model_files(self, dirname):\n",
    "        \"\"\"Create subdirectory and copy relevant model files to it,\n",
    "        then change working directory to subdirectory\"\"\"\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        os.chdir(f\"./{dirname}\")\n",
    "\n",
    "        # Copy needed files from the working directory into the sub-directory\n",
    "        for s in ['model', 'payoff', 'optparm', 'sensitivity', 'savelist', 'senssavelist']:\n",
    "            if getattr(self, s):\n",
    "                copy(f\"../{getattr(self, s)}\", \"./\")\n",
    "        for slist in ['data', 'changes']:\n",
    "            for file in getattr(self, slist):\n",
    "                copy(f\"../{file}\", \"./\")\n",
    "            \n",
    "    def add_suffixes(self, settingsfxs):\n",
    "        \"\"\"Cleanly modifies .cmd script settings with specified suffixes\"\"\"\n",
    "        for s, sfx in settingsfxs.items():\n",
    "            if hasattr(self, s):\n",
    "                self.__setattr__(s, getattr(self, s)[:-4] + sfx + getattr(self, s)[-4:])\n",
    "   \n",
    "    def update_changes(self, chglist, setvals=[]):\n",
    "        \"\"\"Reformats chglist as needed to extend changes settings; \n",
    "        see compile_script for details\"\"\"\n",
    "        # Combines and flattens list of paired change names & suffixes\n",
    "        flatlist = [i for s in \n",
    "                    [[f\"{self.basename}_{n}_{sfx}.out\" for n in name] \n",
    "                     if isinstance(name, list) else [f\"{self.basename}_{name}_{sfx}.out\"] \n",
    "                     for name, sfx in chglist] for i in s]\n",
    "        self.changes.extend(flatlist)\n",
    "        self.setvals = setvals\n",
    "          \n",
    "    def write_script(self, scriptname):\n",
    "        \"\"\"Compiles and writes actual .cmd script file\"\"\"\n",
    "        self.cmdtext.extend([\"SPECIAL>NOINTERACTION\\n\", \n",
    "                             f\"SPECIAL>LOADMODEL|{self.model}\\n\"])\n",
    "        \n",
    "        for s in ['payoff', 'sensitivity', 'optparm', 'savelist', 'senssavelist']:\n",
    "            if hasattr(self, s):\n",
    "                self.cmdtext.append(f\"SIMULATE>{s}|{getattr(self, s)}\\n\")\n",
    "        \n",
    "        if hasattr(self, 'data'):\n",
    "            datatext = ','.join(self.data)\n",
    "            self.cmdtext.append(f\"SIMULATE>DATA|\\\"{','.join(self.data)}\\\"\\n\")\n",
    "\n",
    "        if self.changes:\n",
    "            self.cmdtext.append(f\"SIMULATE>READCIN|{self.changes[0]}\\n\")\n",
    "            for file in self.changes[1:]:\n",
    "                self.cmdtext.append(f\"SIMULATE>ADDCIN|{file}\\n\")\n",
    "        \n",
    "        self.cmdtext.extend([\"\\n\", f\"SIMULATE>RUNNAME|{scriptname}\\n\", \n",
    "                             self.runcmd, self.savecmd, \n",
    "                             \"SPECIAL>CLEARRUNS\\n\", \"MENU>EXIT\\n\"])\n",
    "        \n",
    "        with open(f\"{scriptname}.cmd\", 'w') as scriptfile:\n",
    "            scriptfile.writelines(self.cmdtext)\n",
    "    \n",
    "    def run_script(self, scriptname, controlfile, subdir, logfile):\n",
    "        \"\"\"Runs .cmd script file using function robust to \n",
    "        Vengine errors, and returns payoff value if applicable\"\"\"\n",
    "        return run_vengine_script(scriptname, controlfile['vensimpath'], \n",
    "                                  controlfile['timelimit'], '.log', check_opt, logfile)\n",
    "\n",
    "    \n",
    "class CtyScript(Script):\n",
    "    \"\"\"Script subclass for country optimization runs\"\"\"\n",
    "    def __init__(self, controlfile):\n",
    "        super().__init__(controlfile)\n",
    "        self.genparams = controlfile['genparams'].copy()\n",
    "        \n",
    "    def prep_subdir(self, scriptname, controlfile, subdir):\n",
    "        \"\"\"Creates subdirectory for country-specific files and output\"\"\"\n",
    "        self.copy_model_files(subdir)\n",
    "        copy(f\"../{scriptname}.cmd\", \"./\")\n",
    "        self.genparams.append(f\"[{subdir}]\")\n",
    "        for file in self.changes:\n",
    "            if 'main' in file:\n",
    "                clean_outfile(file, self.genparams)\n",
    "            \n",
    "    def run_script(self, scriptname, controlfile, subdir, logfile):\n",
    "        self.prep_subdir(scriptname, controlfile, subdir)\n",
    "        res = run_vengine_script(scriptname, controlfile['vensimpath'], \n",
    "                                 controlfile['timelimit'], '.log', check_opt, logfile)\n",
    "        copy(f\"./{scriptname}.out\", \"..\") # Copy the .out file to parent directory\n",
    "        os.chdir(\"..\")\n",
    "        return res\n",
    "\n",
    "\n",
    "class CtyMCScript(CtyScript):\n",
    "    \"\"\"Script subclass for country MCMC optimizations\"\"\"\n",
    "    def run_script(self, scriptname, controlfile, subdir, logfile):\n",
    "        self.prep_subdir(scriptname, controlfile, subdir)\n",
    "        res = run_vengine_script(scriptname, controlfile['vensimpath'], \n",
    "                                 controlfile['timelimit'], '_MCMC_points.tab', check_MC, logfile)\n",
    "        os.chdir(\"..\")\n",
    "        return res\n",
    "\n",
    "        \n",
    "class LongScript(Script):\n",
    "    \"\"\"Script subclass for long calibration runs e.g. all-params\"\"\"\n",
    "    def run_script(self, scriptname, controlfile, subdir, logfile):\n",
    "        return run_vengine_script(scriptname, controlfile['vensimpath'], \n",
    "                                  controlfile['timelimit']*5, '.log', check_opt, logfile)\n",
    "        \n",
    "\n",
    "class MultiScript(Script):\n",
    "    \"\"\"Script subclass for running multiple scenarios consecutively \n",
    "    using SETVAL and exporting to a single output file\"\"\"\n",
    "    def write_script(self, scriptname):\n",
    "        self.cmdtext.extend([\"SPECIAL>NOINTERACTION\\n\", \n",
    "                             f\"SPECIAL>LOADMODEL|{self.model}\\n\"])\n",
    "        \n",
    "        for s in ['payoff', 'sensitivity', 'optparm', 'savelist', 'senssavelist']:\n",
    "            if hasattr(self, s):\n",
    "                self.cmdtext.append(f\"SIMULATE>{s}|{getattr(self, s)}\\n\")\n",
    "        \n",
    "        if hasattr(self, 'data'):\n",
    "            datatext = ','.join(self.data)\n",
    "            self.cmdtext.append(f\"SIMULATE>DATA|\\\"{','.join(self.data)}\\\"\\n\")\n",
    "\n",
    "        for varnames, vals, sfx in self.setvals:\n",
    "            if hasattr(self, 'changes'):\n",
    "                self.cmdtext.append(f\"\\nSIMULATE>READCIN|{self.changes[0]}\\n\")\n",
    "                for file in self.changes[1:]:\n",
    "                    self.cmdtext.append(f\"SIMULATE>ADDCIN|{file}\\n\")\n",
    "            self.cmdtext.extend(\n",
    "                [\"\\n\", f\"SIMULATE>RUNNAME|{scriptname}_{sfx}\\n\", \n",
    "                 *[f\"SIMULATE>SETVAL|{var}={val}\\n\" for var, val in zip(varnames, vals)], \n",
    "                 \"MENU>RUN|o\\n\", f\"MENU>VDF2TAB|!|{scriptname}|{self.senssavelist}|+||:!\\n\"])\n",
    "        \n",
    "        self.cmdtext.extend([\"\\n\", \"SPECIAL>CLEARRUNS\\n\", \"MENU>EXIT\\n\"])\n",
    "        \n",
    "        with open(f\"{scriptname}.cmd\", 'w') as scriptfile:\n",
    "            scriptfile.writelines(self.cmdtext)\n",
    "\n",
    "    def run_script(self, scriptname, controlfile, subdir, logfile):\n",
    "        return run_vengine_script(scriptname, controlfile['vensimpath'], \n",
    "                                  controlfile['timelimit']/5, '.vdf', check_multi, logfile)\n",
    "\n",
    "\n",
    "class ScenRunScript(Script):\n",
    "    \"\"\"Script subclass for simple single runs (not optimzations), \n",
    "    optionally with scenario files\"\"\"\n",
    "    def __init__(self, controlfile):\n",
    "        super().__init__(controlfile)\n",
    "        self.runcmd = \"MENU>RUN|o\\n\"\n",
    "    \n",
    "    def update_changes(self, chglist, setvals=None):\n",
    "        scen = []\n",
    "        while True:\n",
    "            try:\n",
    "                if type(chglist[-1]) == str:\n",
    "                    scen.append(chglist.pop())\n",
    "                else: break\n",
    "            except IndexError:\n",
    "                break\n",
    "        super().update_changes(chglist, setvals)\n",
    "        scen.reverse()\n",
    "        self.changes.extend(scen)\n",
    "        chglist.extend(scen)\n",
    "    \n",
    "    def run_script(self, scriptname, controlfile, subdir, logfile):\n",
    "        return run_vengine_script(scriptname, controlfile['vensimpath'], \n",
    "                                  controlfile['timelimit']/5, '.vdf', check_run, logfile)\n",
    "\n",
    "\n",
    "def compile_script(controlfile, scriptclass, name, namesfx, settingsfxs, \n",
    "                   logfile, chglist=[], setvals=[], subdir=None):\n",
    "    \"\"\"Master function for assembling & running .cmd script\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    controlfile : JSON object\n",
    "        Master control file specifying sim settings, runname, etc.\n",
    "    scriptclass : Script object\n",
    "        Type of script object to instantiate, depending on run type\n",
    "    name : str\n",
    "    namesfx : str\n",
    "        Along with `name`, specifies name added to baserunname for run\n",
    "    settingsfxs : dict of str\n",
    "        Dict of suffixes to append to filenames in simsettings; use to \n",
    "        distinguish versions of e.g. .mdl, .voc, .vpd etc. files\n",
    "    logfile : str of filename/path\n",
    "    chglist : list of tuples of (str or list, str)\n",
    "        Specifies changes files to be used in script; specify as tuples \n",
    "        corresponding to `name`, `namesfx` of previous run .out to use; \n",
    "        tuples can also take a list of `names` as first element, taking \n",
    "        each with the same second element; if used with ScenScript run, \n",
    "        `chglist` can also take one non-tuple str as its last element, \n",
    "        which will be added directly (e.g. .cin files for scenarios)\n",
    "    setvals : list of tuples of (str, int or float, <str>)\n",
    "        Specifies variables and values to change for a given run using \n",
    "        Vensim's SETVAL script command; by default all SETVAL commands \n",
    "        will be implemented together for main run, but if `scriptclass` \n",
    "        is MultiScript, each SETVAL command will be implemented and run \n",
    "        separately in sequence; if used with MultiScript, each tuple in \n",
    "        `setvals` will require a third str element specifying the suffix \n",
    "        with which to save the run\n",
    "    subdir : str, optional\n",
    "        Name of subdirectory to create/use for run, if applicable\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Payoff value of the script run, if applicable, else 0\n",
    "    \"\"\"\n",
    "    mainscript = scriptclass(controlfile)\n",
    "    mainscript.add_suffixes(settingsfxs)\n",
    "    mainscript.update_changes(chglist, setvals)\n",
    "    scriptname = f\"{mainscript.basename}_{name}_{namesfx}\"    \n",
    "    mainscript.write_script(scriptname)\n",
    "    return mainscript.run_script(scriptname, controlfile, subdir, logfile)\n",
    "\n",
    "\n",
    "def check_opt(scriptname, logfile):\n",
    "    \"\"\"Check function for use with run_vengine_script for optimizations\"\"\"\n",
    "    if check_zeroes(scriptname):\n",
    "        write_log(f\"Help! {scriptname} is being repressed!\", logfile)\n",
    "    return not check_zeroes(scriptname)\n",
    "\n",
    "def check_MC(scriptname, logfile, threshold=0.01):\n",
    "    \"\"\"Check function for run_vengine_script for MCMC\"\"\"\n",
    "    if abs(compare_payoff(scriptname, logfile)) >= threshold:\n",
    "        write_log(f\"{scriptname} is a self-perpetuating autocracy! re-running MC...\", logfile)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_run(scriptname, logfile):\n",
    "    \"\"\"Check function for run_vengine_script for normal & sens runs\"\"\"\n",
    "    if not os.path.exists(f\"./{scriptname}.vdf\"):\n",
    "        write_log(f\"Help! {scriptname} is being repressed!\", logfile)\n",
    "    return os.path.exists(f\"./{scriptname}.vdf\")\n",
    "\n",
    "def check_multi(scriptname, logfile):\n",
    "    \"\"\"Check function for run_vengine_script for Multiscript runs\"\"\"\n",
    "    if not os.path.exists(f\"./{scriptname}.tab\"):\n",
    "        write_log(f\"Help! {scriptname} is being repressed!\", logfile)\n",
    "    return os.path.exists(f\"./{scriptname}.tab\")\n",
    "\n",
    "\n",
    "def run_vengine_script(scriptname, vensimpath, timelimit, checkfile, check_func, logfile):\n",
    "    \"\"\"Call Vensim with command script using subprocess; monitor output \n",
    "    file for changes to see if Vensim has stalled out, and restart if \n",
    "    it does, or otherwise bugs out; return payoff if applicable\"\"\"\n",
    "\n",
    "    write_log(f\"Initialising {scriptname}!\", logfile)\n",
    "    attempts = 0\n",
    "    while attempts < 30:\n",
    "        proc = subprocess.Popen(f\"{vensimpath} \\\"./{scriptname}.cmd\\\"\")\n",
    "        time.sleep(2)\n",
    "        press('enter') # Necessary to bypass the popup message in Vengine\n",
    "        while True:\n",
    "            try:\n",
    "                # Break out of loop if run completes within specified timelimit\n",
    "                proc.wait(timeout=timelimit)\n",
    "                break\n",
    "            except subprocess.TimeoutExpired:\n",
    "                try:\n",
    "                    # If run not complete before timelimit, check to see if still ongoing\n",
    "                    write_log(f\"Checking for {scriptname}{checkfile}...\", logfile)\n",
    "                    timelag = time.time() - os.path.getmtime(f\"./{scriptname}{checkfile}\")\n",
    "                    if timelag < (timelimit):\n",
    "                        write_log(f\"At {time.ctime()}, {round(timelag,3)}s since last output, \"\n",
    "                                  \"continuing...\", logfile)\n",
    "                        continue\n",
    "                    else:\n",
    "                        # If output isn't being written, kill and restart run\n",
    "                        proc.kill()\n",
    "                        write_log(f\"At {time.ctime()}, {round(timelag,3)}s since last output. \"\n",
    "                                  \"Calibration timed out!\", logfile)\n",
    "                        break\n",
    "                except FileNotFoundError:\n",
    "                    # If output isn't being written, kill and restart run\n",
    "                    proc.kill()\n",
    "                    write_log(\"Calibration timed out!\", logfile)\n",
    "                    break\n",
    "        if proc.returncode != 1: # Note that Vengine returns 1 on MENU>EXIT, not 0!\n",
    "            write_log(f\"Return code is {proc.returncode}\", logfile)\n",
    "            write_log(\"Vensim! Trying again...\", logfile)\n",
    "            continue\n",
    "        try:\n",
    "            # Ensure output is not bugged (specifics depend on type of run)\n",
    "            if check_func(scriptname, logfile):\n",
    "                break\n",
    "            else:\n",
    "                attempts += 1\n",
    "                continue\n",
    "        except FileNotFoundError:\n",
    "            write_log(\"Outfile not found! That's it, I'm dead.\", logfile)\n",
    "            pass\n",
    "    else:\n",
    "        write_log(f\"FAILURE! {scriptname} failed to calibrate!\", logfile)\n",
    "        return False\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "    if os.path.exists(f\"./{scriptname}.out\"):\n",
    "        payoffvalue = read_payoff(f\"{scriptname}.out\")\n",
    "        write_log(f\"Payoff for {scriptname} is {payoffvalue}, calibration complete!\", logfile)\n",
    "        return payoffvalue\n",
    "    return 0 # Set default payoff value for simtypes that don't generate one\n",
    "\n",
    "\n",
    "def clean_outfile(outfilename, linekey):\n",
    "    \"\"\"Clean an outfile to include only lines containing a string in \n",
    "    `linekey`, which should be a list of strings to keep\"\"\"\n",
    "    with open(outfilename,'r') as f:\n",
    "        filedata = f.readlines()\n",
    "\n",
    "    newdata = [line for line in filedata if any(k in line for k in linekey)]\n",
    "    \n",
    "    with open(outfilename, 'w') as f:\n",
    "        f.writelines(newdata)\n",
    "\n",
    "\n",
    "def check_zeroes(scriptname):\n",
    "    \"\"\"Check if an .out file has any parameters set to zero (indicates \n",
    "    Vengine error), return True if any parameters zeroed OR if # runs = \n",
    "    # restarts, and False otherwise\"\"\"\n",
    "    filename = f\"{scriptname}.out\"\n",
    "    with open(filename,'r') as f0:\n",
    "        filedata = f0.readlines()\n",
    "    \n",
    "    checklist = []\n",
    "    for line in filedata:\n",
    "        if line[0] != ':':\n",
    "            if ' = 0 ' in line:\n",
    "                checklist.append(True)\n",
    "            else:\n",
    "                checklist.append(False)\n",
    "        elif ':RESTART_MAX' in line:\n",
    "            restarts = re.findall(r'\\d+', line)[0]\n",
    "    \n",
    "    # Ensure number of simulations != number of restarts\n",
    "    if f\"After {restarts} simulations\" in filedata[0]:\n",
    "        checklist.append(True)\n",
    "        \n",
    "    # Ensure payoff is not erroneous\n",
    "    if abs(read_payoff(filename)) == 1.29807e+33:\n",
    "        checklist.append(True)\n",
    "    \n",
    "    return any(checklist)\n",
    "\n",
    "\n",
    "def write_log(string, logfile):\n",
    "    \"\"\"Writes printed script output to a logfile\"\"\"\n",
    "    with open(logfile,'a') as f:\n",
    "        f.write(string + \"\\n\")\n",
    "    print(string)\n",
    "\n",
    "    \n",
    "def modify_mdl(country, finaltime, modelname, newmodelname):\n",
    "    \"\"\"Opens .mdl as text, identifies Rgn subscript, and replaces \n",
    "    with appropriate country name\"\"\"\n",
    "    with open(modelname,'r') as f:\n",
    "        filedata = f.read()\n",
    "        \n",
    "    rgnregex = re.compile(r\"Rgn(\\s)*?:(\\n)?[\\s\\S]*?(\\n\\t~)\")\n",
    "    timeregex = re.compile(r\"FINAL TIME\\s*=\\s*\\d*\\n\")\n",
    "    tempdata = rgnregex.sub(f\"Rgn:\\n\\t{country}\\n\\t~\", filedata)\n",
    "    newdata = timeregex.sub(f\"FINAL TIME = {finaltime}\\n\", tempdata)\n",
    "\n",
    "    with open(newmodelname,'w') as f:\n",
    "        f.write(newdata)\n",
    "\n",
    "\n",
    "def split_voc(vocname, mcsettings):\n",
    "    \"\"\"Splits .VOC file into multiple versions, for main, country, \n",
    "    initial, full model, general MCMC, and country MCMC calibration\"\"\"\n",
    "    with open(vocname,'r') as f0:\n",
    "        filedata = f0.readlines()\n",
    "    \n",
    "    voccty = [line for line in filedata if line[0] == ':' or '[Rgn]' in line]\n",
    "    vocfull = filedata.copy()\n",
    "\n",
    "    # Turn off multiple start for full voc\n",
    "    for l, line in enumerate(vocfull):\n",
    "        if ':MULTIPLE_START' in line:\n",
    "            vocfull[l] = ':MULTIPLE_START=OFF\\n'\n",
    "\n",
    "    # Make necessary substitutions for MCMC settings\n",
    "    vocctymc = ''.join(voccty)\n",
    "    for k,v in mcsettings.items():\n",
    "        vocctymc = re.sub(f\":{re.escape(k)}=.*\", f\":{k}={v}\", vocctymc)\n",
    "        \n",
    "    # Write various voc versions to separate .voc files\n",
    "    for fname, suffix in zip([voccty, vocfull, vocctymc], \n",
    "                             ['c', 'f', 'cmc']):\n",
    "        with open(f\"{vocname[:-4]}_{suffix}.voc\", 'w') as f:\n",
    "            f.writelines(fname)\n",
    "\n",
    "\n",
    "def create_mdls(controlfile, countrylist, finaltime, logfile):\n",
    "    \"\"\"Creates copies of the base .mdl file for each country in list \n",
    "    (and one main copy) and splits .VOC files\"\"\"\n",
    "    model = controlfile['simsettings']['model']\n",
    "    for c in countrylist:\n",
    "        newmodel = model[:-4] + f'_{c}.mdl'\n",
    "        modify_mdl(c, finaltime, model, newmodel)\n",
    "\n",
    "    mainmodel = model[:-4] + '_main.mdl'\n",
    "    c_list = [f'{c}\\\\\\n\\t\\t' if i % 10 == 9 else c for i,c in enumerate(countrylist)]\n",
    "    countrylist_str = str(c_list)[1:-1].replace(\"'\",\"\")\n",
    "    modify_mdl(countrylist_str, finaltime, model, mainmodel)\n",
    "    split_voc(controlfile['simsettings']['optparm'], controlfile['mcsettings'])\n",
    "    write_log(\"Files are ready! moving to calibration\", logfile)\n",
    "\n",
    "\n",
    "def read_payoff(outfile, line=1):\n",
    "    \"\"\"Identifies payoff value from .OUT or .REP file - \n",
    "    use line 1 (default) for .OUT, or use line 0 for .REP\"\"\"\n",
    "    with open(outfile) as f:\n",
    "        payoffline = f.readlines()[line]\n",
    "    payoffvalue = [float(s) for s in \n",
    "                   re.findall(r'-?(?:0|[1-9]\\d*)(?:\\.\\d*)?(?:[eE][+\\-]?\\d+)?', payoffline)][0]\n",
    "    return payoffvalue\n",
    "\n",
    "\n",
    "def compare_payoff(scriptname, logfile):\n",
    "    \"\"\"Returns the difference in payoffs between .OUT and .REP file, \n",
    "    which should be zero in most cases except when MCMC bugs out\"\"\"\n",
    "    try:\n",
    "        difference = read_payoff(f\"{scriptname}.out\") - read_payoff(f\"{scriptname}.rep\", 0)\n",
    "        write_log(f\".OUT and .REP payoff difference is {difference}\", logfile)\n",
    "        return difference\n",
    "    except IndexError:\n",
    "        return 1e33\n",
    "\n",
    "\n",
    "def increment_seed(vocfile, logfile):\n",
    "    \"\"\"Increments random number seed in a .VOC file by 1\"\"\"\n",
    "    with open(vocfile, 'r') as f:\n",
    "        vocdata = f.read()\n",
    "    seedregex = re.compile(r':SEED=\\d+')\n",
    "    try:\n",
    "        i = int(re.search(r'\\d+', re.search(seedregex, vocdata).group()).group())\n",
    "        newdata = seedregex.sub(f\":SEED={i+1}\", vocdata)\n",
    "        with open(vocfile, 'w') as f:\n",
    "            f.write(newdata)\n",
    "    except:\n",
    "        write_log(\"No seed found, skipping incrementing.\", logfile)    \n",
    "\n",
    "\n",
    "def read_outvals(outfile):\n",
    "    \"\"\"Converts .out file into list of tuples of var names & values\"\"\"\n",
    "    with open(outfile, 'r') as f:\n",
    "        output = [line for line in f.readlines() if (line[0] != ':')]\n",
    "\n",
    "    names = [line.split('<=')[1].split('=')[0].strip() for line in output]\n",
    "    values = [float(line.split('<=')[1].split('=')[1]) for line in output]\n",
    "    \n",
    "    return list(zip(names, values))\n",
    "\n",
    "\n",
    "def read_value(outfile, varname):\n",
    "    \"\"\"Reads & returns a specified variable's value from an outfile\"\"\"\n",
    "    with open(outfile, 'r') as f:\n",
    "        output = [line for line in f.readlines() if (line[0] != ':')]\n",
    "        \n",
    "    for line in output:\n",
    "        if varname in line:\n",
    "            val = float(line.split('<=')[1].split('=')[1])\n",
    "    \n",
    "    return val\n",
    "\n",
    "\n",
    "##### FUNCTION DEFINITIONS FOR ANALYSIS & DATA PROCESSING #####\n",
    "\n",
    "def get_first_idx(s, threshold):\n",
    "    \"\"\"Return index of first value in series `s` above `threshold`\"\"\"\n",
    "    return (s > threshold).idxmax(skipna=True)\n",
    "\n",
    "\n",
    "def calc_eq_vals(df, eqtime, colnames=['eq_gdn', 'eq_alpha', 'eq_dpm'], duration=None):\n",
    "    \"\"\"Calculate equilibrium gdn, dpm, and alpha values projected for \n",
    "    `eqtime` based on `duration`, modifying dataframe in place with \n",
    "    additional columns as specified in `colnames` list\"\"\"\n",
    "    # Override duration if specified, else take default from dataframe\n",
    "    if duration:\n",
    "        dur = duration\n",
    "    else:\n",
    "        dur = df['DiseaseDuration']\n",
    "        \n",
    "    # Then calculate projected equilibrium values; see model for details\n",
    "    df[colnames[0]] = 1 / (df['beta'] * dur)\n",
    "    df[colnames[1]] = (df['alpha 0'] + 1 / (1 + np.exp(-(eqtime - df['t0'])/df['theta']))\n",
    "                      * (df['alpha f'] - df['alpha 0']))\n",
    "    df[colnames[2]] = np.log(df['beta'] * dur) / df[colnames[1]]\n",
    "    \n",
    "\n",
    "def calc_end_vals(df, cum_dpm, ifr, endtime, delta=None, cum_dpm_del=None, duration=None):\n",
    "    \"\"\"Calculate equilibrium SFrac, gdn, dpm, and alpha values projected \n",
    "    at `endtime` of run based on `duration` and `cum_dpm`, modifying \n",
    "    dataframe in place; also calculates values for `delta` (int) time \n",
    "    units before end time if delta is specified\"\"\"\n",
    "    # Override duration if specified, else take default from dataframe\n",
    "    if duration:\n",
    "        dur = duration\n",
    "    else:\n",
    "        dur = df['DiseaseDuration']\n",
    "        \n",
    "    # Then calculate projected equilibrium values; see model for details\n",
    "    df['SFrac'] = 1 - (cum_dpm * df['DeathReportingRatio']/ifr)/1e+06\n",
    "    df['end_alpha'] = (df['alpha 0'] + 1 / (1 + np.exp(-(endtime - df['t0'])/df['theta'])) \n",
    "                       * (df['alpha f'] - df['alpha 0']))\n",
    "    df['end_dpm'] = np.log(df['beta'] * df['SFrac'] * dur) / df['end_alpha']\n",
    "    df['end_gdn'] = np.exp(-df['end_alpha']*df['end_dpm'])\n",
    "    \n",
    "    # If delta time is specified, calculate projected values at `endtime` - `delta`\n",
    "    if delta:\n",
    "        df['SFrac_del'] = 1 - (cum_dpm_del * df['DeathReportingRatio']/ifr)/1e+06\n",
    "        df['del_alpha'] = (df['alpha 0'] + 1 / (1 + np.exp(-(\n",
    "            (endtime - delta) - df['t0'])/df['theta'])) * (df['alpha f'] - df['alpha 0']))\n",
    "        df['del_dpm'] = np.log(df['beta'] * df['SFrac_del'] * dur) / df['del_alpha']\n",
    "        df['del_gdn'] = np.exp(-df['del_alpha']*df['del_dpm'])\n",
    "        \n",
    "        # Normalise change in value and average over `delta`\n",
    "        df['chg_dpm_raw'] = (df['end_dpm'] - df['del_dpm'])/df['end_dpm']\n",
    "        df['chg_dpm'] = df['chg_dpm_raw']/delta\n",
    "    \n",
    "\n",
    "def generate_intervals(scriptname, cum_dpm, ifr, eqtime, endtime, iqr_list, \n",
    "                       perc_list, delta=None, cum_dpm_del=None, duration=None):\n",
    "    \"\"\"Generate credible intervals and IQRs using percentiles of results \n",
    "    from MCMC output, returning IQRs for variables in `iqr_list` and \n",
    "    percentiles specified in `perc_list` for hardcoded variables\"\"\"\n",
    "    # Read in MCMC sample output\n",
    "    samdf = pd.read_csv(f\"{scriptname}_MCMC_sample.tab\", sep='\\t')\n",
    "    samdf.columns = [col.split('[')[0] for col in samdf.columns]\n",
    "    \n",
    "    # Calculate quasi-equilibrium values at specified times for all runs in MCMC sample\n",
    "    calc_eq_vals(samdf, eqtime, duration=duration)\n",
    "    calc_end_vals(samdf, cum_dpm, ifr, endtime, delta, cum_dpm_del, duration)\n",
    "    \n",
    "    # Identify percentiles for quasi-equilibrum values based on `perc_list`\n",
    "    percs = [samdf[var].quantile(perc_list) for var in \n",
    "             ['eq_gdn', 'eq_dpm', 'end_gdn', 'end_dpm', 'chg_dpm']]\n",
    "    \n",
    "    for perc, var in zip(percs, ['eq_gdn', 'eq_dpm', 'end_gdn', 'end_dpm', 'chg_dpm']):\n",
    "        perc.index = [f'{var}_{i}' for i in perc_list]\n",
    "    \n",
    "    # Calculate IQRs for vars in `iqr_list` based on percentiles in MCMC sample\n",
    "    iqr_vals = [(samdf[var].quantile(0.75) - samdf[var].quantile(0.25)) for var in iqr_list]\n",
    "    iqrs = pd.Series(iqr_vals, index=[f'{var}_iqr' for var in iqr_list])\n",
    "    \n",
    "    return iqrs, percs\n",
    "\n",
    "\n",
    "def calc_mean(resdf, var, limit=180):\n",
    "    \"\"\"Return mean of `var` over historical period given by `limit`\"\"\"\n",
    "    limit = min(len(resdf.loc[var]), limit)\n",
    "    val = resdf.loc[var][-limit:].mean()\n",
    "    return val\n",
    "\n",
    "\n",
    "def calc_gof(resdf, simvar, datavar):\n",
    "    \"\"\"Calculate goodness-of-fit measures for given sim & data vars\"\"\"\n",
    "    resdf.loc['error'] = abs(resdf.loc[simvar] - resdf.loc[datavar])\n",
    "    maeom = resdf.loc['error'].mean()/resdf.loc[datavar].mean()\n",
    "    mape = (resdf.loc['error']/resdf.loc[datavar]).mean()\n",
    "    r2 = (resdf.loc[simvar].corr(resdf.loc[datavar])) ** 2\n",
    "    return maeom, mape, r2\n",
    "\n",
    "\n",
    "def trunc_log(df):\n",
    "    \"\"\"Return log10 of a dataframe, ignoring negative base values\"\"\"\n",
    "    df[df <= 0] = np.NaN\n",
    "    return np.log10(df)\n",
    "\n",
    "\n",
    "def process_results(scriptname, eqtime, earlytime, gof_vars, iqr_list=[], \n",
    "                    means_list=[], perc_list=[0.05,0.95], delta=None, duration=None):\n",
    "    \"\"\"Read single-country calibration results and calculate additional \n",
    "    outputs, incl. percentiles and IQRs, returning a compiled pd.Series \n",
    "    of processed country results `c_res` and a Dataframe with country \n",
    "    time series outputs (deaths & infs) `datdf`\"\"\"\n",
    "    # Read country parameter values from .out file\n",
    "    outlist = read_outvals(f'{scriptname}.out')\n",
    "    varnames = [n.split('[')[0] for n in [var[0] for var in outlist]]\n",
    "    vals = [var[1] for var in outlist]\n",
    "    c_res = pd.Series(vals, index=varnames)\n",
    "    \n",
    "    # Read full country calibration results, extract death & inf data for output\n",
    "    resdf = pd.read_csv(f'{scriptname}.tab', sep='\\t', index_col=0, error_bad_lines=False)\n",
    "    resdf.index = [n.split('[')[0] for n in resdf.index] # Separate subscripts\n",
    "    datdf = resdf.loc[['DeathsOverTimeRaw', 'eqDeath', 'DataFlowOverTime', 'inf exp']]\n",
    "    \n",
    "    # Pull end-of-run values from full country results\n",
    "    endtime = len(resdf.columns) - 1\n",
    "    c_res['cum_dpm'] = resdf.loc['CumulativeDpm'][-1]\n",
    "    c_res['cum_dpm_del'] = resdf.loc['CumulativeDpm'][-(1 + delta)]\n",
    "    c_res['IFR'] = resdf.loc['IFR'][0]\n",
    "    c_res['SFrac_mdl'] = resdf.loc['SFrac'][-1]\n",
    "    c_res['end_dpm_mdl'] = resdf.loc['eqDeath'][-1]\n",
    "    c_res['end_alpha_mdl'] = resdf.loc['alpha'][-1]\n",
    "    c_res['end_gdn_mdl'] = resdf.loc['g death'][-1]\n",
    "    c_res['chg_dpm_mdl'] = (c_res['end_dpm_mdl'] - resdf.loc['eqDeath'][-2])/c_res['end_dpm_mdl']\n",
    "    \n",
    "    # Calculate mean Re and GOF statistics\n",
    "    for var in means_list:\n",
    "        c_res[f\"avg_{var}\"] = calc_mean(resdf, var, limit=hist_window)\n",
    "    c_res['maeom'], c_res['mape'], c_res['r2'] = calc_gof(resdf, gof_vars[0], gof_vars[1])\n",
    "    \n",
    "    # Calculate various projections based on analytical approximation\n",
    "    calc_eq_vals(c_res, eqtime, duration=duration) # for projected eqtime\n",
    "    calc_end_vals(c_res, c_res['cum_dpm'], c_res['IFR'], \n",
    "                  endtime, delta, c_res['cum_dpm_del'], duration) # for end of run\n",
    "    calc_eq_vals(c_res, earlytime, colnames=['ear_gdn', 'ear_alpha', 'ear_dpm'], \n",
    "                 duration=duration) # for estimate of early responsiveness\n",
    "\n",
    "    # Calculate IQR and percentile values to append to country results\n",
    "    iqrs, percs = generate_intervals(scriptname, c_res['cum_dpm'], c_res['IFR'], eqtime, endtime, \n",
    "                                     iqr_list, perc_list, delta, c_res['cum_dpm_del'], duration)\n",
    "    c_res = pd.concat([c_res, iqrs, *percs])\n",
    "    \n",
    "    return c_res, datdf\n",
    "\n",
    "\n",
    "def regress_deaths(dthdf):\n",
    "    \"\"\"Read in death and expected equilibrium death data, and regress \n",
    "    for all countries day by day, recording regression coefficients\"\"\"\n",
    "    regdf = pd.DataFrame(index=dthdf.columns, columns=['n_R', 'RLM'])\n",
    "\n",
    "    for i in dthdf.columns:\n",
    "        # Correct for negative values and take log10\n",
    "        Y_log = trunc_log(dthdf.loc['dpm'][i])\n",
    "        X_log = trunc_log(dthdf.loc['eqDeath'][i])\n",
    "\n",
    "        # If insufficient datapoints for date, skip and record NaN\n",
    "        if Y_log.count() < 3:\n",
    "            regdf.loc[i] = np.NaN\n",
    "        \n",
    "        # Otherwise run robust linear regression\n",
    "        else:\n",
    "            mod_RLM = sm.RLM(Y_log, X_log, missing='drop')\n",
    "            fit_RLM = mod_RLM.fit()\n",
    "            \n",
    "            # Record observations and coefficient\n",
    "            regdf.loc[i] = [fit_RLM.nobs, fit_RLM.params[0]]\n",
    "    \n",
    "    regdf.to_csv(f'./{baserunname}_regression.tab', sep='\\t')\n",
    "    \n",
    "    return regdf\n",
    "\n",
    "\n",
    "def compile_senslist(sens_vars, vals_dict, multipliers):\n",
    "    \"\"\"Compile setvals list for use with MultiScript for sensitivity \n",
    "    analysis, based on specified `multipliers` and parameters to test \n",
    "    as listed in `sens_vars`\"\"\"\n",
    "    def lookup_dict(vars_list, vals_list):\n",
    "        return [type(sub)(vals_list[var] for var in sub) for sub in vars_list]\n",
    "\n",
    "    def lookup_mult(vars_list, mult):\n",
    "        return [type(sub)(var * mult for var in sub) for sub in vars_list]\n",
    "\n",
    "    # Pull corresponding values for sensitivity parameters\n",
    "    base_vals = lookup_dict(sens_vars, vals_dict)\n",
    "    \n",
    "    # Generate suffix strings for runnames\n",
    "    sfxs = [str(mult).replace('.','') for mult in multipliers]\n",
    "\n",
    "    # Calculate setval values for sensitivity parameters\n",
    "    mult_list = [lookup_mult(base_vals, mult) for mult in multipliers]\n",
    "\n",
    "    # Compile & return list of setval tuples\n",
    "    sens_list = [[(varnames, mults[i], sfxs[j]) for j, mults in enumerate(mult_list)] \n",
    "                 for i, varnames in enumerate(sens_vars)]\n",
    "\n",
    "    return sens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter control file name (with extension):CRV11.txt\n"
     ]
    }
   ],
   "source": [
    "controlfilename = input(\"Enter control file name (with extension):\")\n",
    "cf = json.load(open(controlfilename, 'r'))\n",
    "\n",
    "# Unpack controlfile into variables\n",
    "for k,v in cf.items():\n",
    "    exec(k + '=v')\n",
    "\n",
    "for k,v in datasettings.items():\n",
    "    exec(k + '=v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tseyang.lim\\\\Desktop\\\\CovReg\\\\S_IterCal'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising <__main__.Script object at 0x0000021E4E8CD580>\n",
      "-----\n",
      "Starting new log at Thu Dec 10 14:22:39 2020\n",
      "Ready to work!\n"
     ]
    }
   ],
   "source": [
    "# Set up files in run directory and initialise logfile\n",
    "master = Script(cf)\n",
    "master.changes.extend(scenariolist)\n",
    "master.copy_model_files(f\"{baserunname}_IterCal\")\n",
    "for f in [f\"../{controlfilename}\", \"../ImportData.cmd\", \"../CovRegInput.frm\"]:\n",
    "    copy(f, \"./\")\n",
    "logfile = f\"{os.getcwd()}/{baserunname}.log\"\n",
    "write_log(f\"-----\\nStarting new log at {time.ctime()}\\nReady to work!\", logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AND', 'ATG', 'BDI', 'BEN', 'BFA', 'BHS', 'BLZ', 'BRB', 'BRN', 'BTN',\n",
      "       'CAF', 'COG', 'COM', 'CUB', 'DJI', 'DMA', 'ERI', 'FJI', 'GAB', 'GMB',\n",
      "       'GNB', 'GNQ', 'GRD', 'GUY', 'HTI', 'ISL', 'KHM', 'KNA', 'LAO', 'LBR',\n",
      "       'LCA', 'LIE', 'LSO', 'MCO', 'MHL', 'MLI', 'MNG', 'MUS', 'MWI', 'NER',\n",
      "       'NIC', 'NZL', 'PNG', 'RWA', 'SLB', 'SLE', 'SMR', 'SOM', 'SSD', 'STP',\n",
      "       'SUR', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TLS', 'TTO', 'TWN',\n",
      "       'TZA', 'URY', 'VAT', 'VCT', 'VNM', 'VUT', 'WSM', 'YEM'],\n",
      "      dtype='object', name='iso_code') Index(['BTN', 'DMA', 'ERI', 'GRD', 'KHM', 'KNA', 'LAO', 'MHL', 'MNG', 'SLB',\n",
      "       'SYC', 'TLS', 'VAT', 'VCT', 'VUT', 'WSM'],\n",
      "      dtype='object', name='iso_code') Index([], dtype='object', name='iso_code')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th>iso_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">new_cases</th>\n",
       "      <th>AFG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>183.714</td>\n",
       "      <td>191.714</td>\n",
       "      <td>190.571</td>\n",
       "      <td>176.714</td>\n",
       "      <td>159.143</td>\n",
       "      <td>175.429</td>\n",
       "      <td>170.000</td>\n",
       "      <td>177.429</td>\n",
       "      <td>171.429</td>\n",
       "      <td>161.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>72.143</td>\n",
       "      <td>72.714</td>\n",
       "      <td>71.143</td>\n",
       "      <td>63.000</td>\n",
       "      <td>69.286</td>\n",
       "      <td>64.143</td>\n",
       "      <td>69.714</td>\n",
       "      <td>72.714</td>\n",
       "      <td>68.286</td>\n",
       "      <td>69.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>660.857</td>\n",
       "      <td>673.429</td>\n",
       "      <td>682.143</td>\n",
       "      <td>700.143</td>\n",
       "      <td>722.429</td>\n",
       "      <td>765.429</td>\n",
       "      <td>766.143</td>\n",
       "      <td>785.857</td>\n",
       "      <td>774.571</td>\n",
       "      <td>781.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1257.857</td>\n",
       "      <td>1254.857</td>\n",
       "      <td>1253.143</td>\n",
       "      <td>1254.857</td>\n",
       "      <td>1258.857</td>\n",
       "      <td>1253.429</td>\n",
       "      <td>1239.429</td>\n",
       "      <td>1245.286</td>\n",
       "      <td>1241.143</td>\n",
       "      <td>1245.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7128.857</td>\n",
       "      <td>7253.571</td>\n",
       "      <td>7102.143</td>\n",
       "      <td>6900.143</td>\n",
       "      <td>6764.857</td>\n",
       "      <td>6636.714</td>\n",
       "      <td>6329.000</td>\n",
       "      <td>5968.000</td>\n",
       "      <td>5335.571</td>\n",
       "      <td>5017.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">total_cases</th>\n",
       "      <th>VEN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>102394.000</td>\n",
       "      <td>102621.000</td>\n",
       "      <td>103067.000</td>\n",
       "      <td>103548.000</td>\n",
       "      <td>103877.000</td>\n",
       "      <td>104177.000</td>\n",
       "      <td>104442.000</td>\n",
       "      <td>104904.000</td>\n",
       "      <td>105384.000</td>\n",
       "      <td>105852.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XKX</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39596.000</td>\n",
       "      <td>40117.000</td>\n",
       "      <td>40117.000</td>\n",
       "      <td>40117.000</td>\n",
       "      <td>40117.000</td>\n",
       "      <td>42337.000</td>\n",
       "      <td>42805.000</td>\n",
       "      <td>43324.000</td>\n",
       "      <td>43881.000</td>\n",
       "      <td>44442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZAF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>790004.000</td>\n",
       "      <td>792299.000</td>\n",
       "      <td>796472.000</td>\n",
       "      <td>800872.000</td>\n",
       "      <td>805804.000</td>\n",
       "      <td>810449.000</td>\n",
       "      <td>814565.000</td>\n",
       "      <td>817878.000</td>\n",
       "      <td>821889.000</td>\n",
       "      <td>828598.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZMB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17647.000</td>\n",
       "      <td>17665.000</td>\n",
       "      <td>17700.000</td>\n",
       "      <td>17730.000</td>\n",
       "      <td>17857.000</td>\n",
       "      <td>17898.000</td>\n",
       "      <td>17916.000</td>\n",
       "      <td>17931.000</td>\n",
       "      <td>17963.000</td>\n",
       "      <td>18062.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9950.000</td>\n",
       "      <td>10129.000</td>\n",
       "      <td>10129.000</td>\n",
       "      <td>10424.000</td>\n",
       "      <td>10547.000</td>\n",
       "      <td>10617.000</td>\n",
       "      <td>10718.000</td>\n",
       "      <td>10839.000</td>\n",
       "      <td>10912.000</td>\n",
       "      <td>11007.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 344 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                  1    2    3    4    5    6    7    8    9    10   ...  \\\n",
       "field       iso_code                                                    ...   \n",
       "new_cases   AFG       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            AGO       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            ALB       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            ARE       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            ARG       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "...                   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "total_cases VEN       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            XKX       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            ZAF       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            ZMB       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "            ZWE       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "\n",
       "date                         335         336         337         338  \\\n",
       "field       iso_code                                                   \n",
       "new_cases   AFG          183.714     191.714     190.571     176.714   \n",
       "            AGO           72.143      72.714      71.143      63.000   \n",
       "            ALB          660.857     673.429     682.143     700.143   \n",
       "            ARE         1257.857    1254.857    1253.143    1254.857   \n",
       "            ARG         7128.857    7253.571    7102.143    6900.143   \n",
       "...                          ...         ...         ...         ...   \n",
       "total_cases VEN       102394.000  102621.000  103067.000  103548.000   \n",
       "            XKX        39596.000   40117.000   40117.000   40117.000   \n",
       "            ZAF       790004.000  792299.000  796472.000  800872.000   \n",
       "            ZMB        17647.000   17665.000   17700.000   17730.000   \n",
       "            ZWE         9950.000   10129.000   10129.000   10424.000   \n",
       "\n",
       "date                         339         340         341         342  \\\n",
       "field       iso_code                                                   \n",
       "new_cases   AFG          159.143     175.429     170.000     177.429   \n",
       "            AGO           69.286      64.143      69.714      72.714   \n",
       "            ALB          722.429     765.429     766.143     785.857   \n",
       "            ARE         1258.857    1253.429    1239.429    1245.286   \n",
       "            ARG         6764.857    6636.714    6329.000    5968.000   \n",
       "...                          ...         ...         ...         ...   \n",
       "total_cases VEN       103877.000  104177.000  104442.000  104904.000   \n",
       "            XKX        40117.000   42337.000   42805.000   43324.000   \n",
       "            ZAF       805804.000  810449.000  814565.000  817878.000   \n",
       "            ZMB        17857.000   17898.000   17916.000   17931.000   \n",
       "            ZWE        10547.000   10617.000   10718.000   10839.000   \n",
       "\n",
       "date                         343         344  \n",
       "field       iso_code                          \n",
       "new_cases   AFG          171.429     161.857  \n",
       "            AGO           68.286      69.286  \n",
       "            ALB          774.571     781.286  \n",
       "            ARE         1241.143    1245.143  \n",
       "            ARG         5335.571    5017.000  \n",
       "...                          ...         ...  \n",
       "total_cases VEN       105384.000  105852.000  \n",
       "            XKX        43881.000   44442.000  \n",
       "            ZAF       821889.000  828598.000  \n",
       "            ZMB        17963.000   18062.000  \n",
       "            ZWE        10912.000   11007.000  \n",
       "\n",
       "[357 rows x 344 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### THIS CELL IS FOR UPDATING DATA ONLY #####\n",
    "\n",
    "data = pd.read_csv(data_url) # Read data from URL for raw data CSV\n",
    "\n",
    "# Subset CSV to relevant data fields\n",
    "data = data.filter(['iso_code','date', 'total_cases', 'new_cases_smoothed', \n",
    "                    'new_deaths_smoothed_per_million', 'population', 'gdp_per_capita'], axis=1)\n",
    "\n",
    "# Rename fields as needed\n",
    "data.columns = ['iso_code','date', 'total_cases', 'new_cases', \n",
    "                'new_dpm', 'population', 'gdp_per_capita']\n",
    " \n",
    "table = pd.pivot_table(data, values=['total_cases', 'new_cases', 'new_dpm', 'population', \n",
    "                                     'gdp_per_capita'], index='date', columns='iso_code')\n",
    "table = table.T\n",
    "table.index.names = ['field', 'iso_code']\n",
    "table.columns = pd.to_datetime(table.columns)\n",
    "\n",
    "# Drop countries with fewer cases than specified threshold, insufficient datapoints, or zero deaths\n",
    "dropidx_cases = table.loc['total_cases'].index[table.loc['total_cases'].max(axis=1) < min_cases]\n",
    "dropidx_deaths = table.loc['new_dpm'].index[table.loc['new_dpm'].max(axis=1) == 0]\n",
    "first_idxs = (table.loc['total_cases'] > start_cases).idxmax(axis=1)\n",
    "dropidx_data = table.loc['total_cases'].index[\n",
    "    (table.columns[-1] - first_idxs).dt.days < min_datapoints]\n",
    "print(dropidx_cases, dropidx_deaths, dropidx_data)\n",
    "table.drop(dropidx_cases, level='iso_code', inplace=True, errors='ignore')\n",
    "table.drop(dropidx_deaths, level='iso_code', inplace=True, errors='ignore')\n",
    "table.drop(dropidx_data, level='iso_code', inplace=True, errors='ignore')\n",
    "table.drop(droplist, level='iso_code', inplace=True, errors='ignore')\n",
    "\n",
    "table = table.rename(index=renames) # Rename any unusual ISO codes as needed\n",
    "\n",
    "# Separate country statistics columns for later use, then temporarily remove\n",
    "popn = table.loc['population'].mean(axis=1)\n",
    "gdppc = table.loc['gdp_per_capita'].mean(axis=1)\n",
    "\n",
    "table.drop(['population', 'gdp_per_capita'], level='field', inplace=True, errors='ignore')\n",
    "\n",
    "# Convert column indices to day number since startdate\n",
    "table.columns = (table.columns - pd.to_datetime('2019-12-31')).days\n",
    "\n",
    "# Reorder multiindex levels before by-country subsetting\n",
    "table = table.reorder_levels(['iso_code', 'field']).sort_index()\n",
    "\n",
    "# Identify first date over infection threshold for each country and subset dataframe accordingly\n",
    "for i in table.index.levels[0]:\n",
    "    first_idx = get_first_idx(table.loc[i].loc['total_cases'], start_cases)\n",
    "    table.loc[i].loc[:, :first_idx] = np.NaN\n",
    "\n",
    "# Clean infinite values and switch multiindex levels back\n",
    "table.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "table = table.reorder_levels(['field', 'iso_code']).sort_index()\n",
    "\n",
    "# Calculate aggregate dpm data for later use\n",
    "mean_dpm = table.loc['new_dpm'][-hist_window:].mean(axis=1) # Mean over last `hist_window` days\n",
    "\n",
    "# Export processed dataframe to .tab and import to VDF, or read in existing .tab\n",
    "display(table)\n",
    "if updatedata != 0:\n",
    "    table.to_csv(f'./InputData.tab', sep='\\t')\n",
    "    subprocess.run(f\"{vensim7path} \\\"./ImportData.cmd\\\"\", check=True)\n",
    "else:\n",
    "    table = pd.read_csv(f'./InputData.tab', sep='\\t', index_col=[0,1])\n",
    "\n",
    "# Update FinalTime cin with last day of available data - IMPORTANT! USES LAST FILE IN CHANGES LIST\n",
    "finaltime = len(table.columns)-1\n",
    "with open(simsettings['changes'][0], 'w') as f:\n",
    "    f.write(f\"FINAL TIME = {finaltime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'AUS', 'AUT', 'AZE', 'BEL', 'BGD', 'BGR', 'BHR', 'BIH', 'BLR', 'BOL', 'BRA', 'BWA', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'COD', 'COL', 'CPV', 'CRI', 'CYP', 'CZE', 'DEU', 'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ESP', 'EST', 'ETH', 'FIN', 'FRA', 'GBR', 'GEO', 'GHA', 'GIN', 'GRC', 'GTM', 'HND', 'HRV', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KOR', 'KWT', 'LBN', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', 'MDG', 'MDV', 'MEX', 'MKD', 'MLT', 'MMR', 'MNE', 'MOZ', 'MYS', 'NAM', 'NGA', 'NLD', 'NOR', 'NPL', 'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'POL', 'PRY', 'PSE', 'QAT', 'ROU', 'RUS', 'SAU', 'SDN', 'SEN', 'SGP', 'SLV', 'SRB', 'SVK', 'SVN', 'SWE', 'TJK', 'TUN', 'TUR', 'UGA', 'UKR', 'USA', 'UZB', 'VEN', 'XKX', 'ZAF', 'ZMB', 'ZWE']\n"
     ]
    }
   ],
   "source": [
    "##### MAIN ANALYSIS, DURATION SENSITIVITY & RESULTS-PROCESSING CODE #####\n",
    "\n",
    "# Pull country list from data table\n",
    "countrylist = list(table.index.levels[1])\n",
    "print(countrylist)\n",
    "\n",
    "basename = cf['baserunname']\n",
    "\n",
    "# Loop through disease duration values to test, starting with main then sensitivity values\n",
    "for i in ([main_dur] + sens_durs):\n",
    "    cf['baserunname'] = f'{basename}{i}'\n",
    "    baserunname = cf['baserunname']\n",
    "    print(baserunname)\n",
    "\n",
    "    # Create script object for given duration, to cleanly create calibration subfolder\n",
    "    sub = Script(cf)\n",
    "    sub.changes.extend(scenariolist)\n",
    "    sub.copy_model_files(baserunname)\n",
    "    copy(f\"../{controlfilename}\", \"./\")\n",
    "    \n",
    "    # Overwrite disease duration cin file - IMPORTANT! USES LAST FILE IN CHANGES LIST\n",
    "    with open(simsettings['changes'][-1], 'w') as f:\n",
    "        f.write(f\"DiseaseDuration = {i}\")\n",
    "        \n",
    "    dur = i # Assign disease duration variable\n",
    "    \n",
    "    # Initialise necessary .mdl and .voc files\n",
    "    create_mdls(cf, countrylist, finaltime, logfile)\n",
    "    \n",
    "    # Run country-by-country calibration process, unless otherwise specified (mccores=0)\n",
    "    if mccores != 0:\n",
    "        write_log(f\"Initialising MCMC with duration {dur}!\", logfile)\n",
    "        c_list = []\n",
    "        err_list = []\n",
    "        for c in countrylist:\n",
    "            # First run Powell optimization, then MCMC\n",
    "            res_i = compile_script(cf, CtyScript, c, 'i', {'model': f'_{c}', 'optparm': '_c'}, \n",
    "                                   logfile, subdir=c)\n",
    "            if res_i != False:\n",
    "                res = compile_script(cf, CtyMCScript, c, 'MC', {'model': f'_{c}', 'optparm': '_cmc'}, \n",
    "                                     logfile, chglist=[(c, 'i')], subdir=c)\n",
    "                if res != False:\n",
    "                    c_list.append(c) # Compile updated c_list of successful calibrations\n",
    "                else:\n",
    "                    err_list.append(c) # Compile error list of failed calibrations\n",
    "            else:\n",
    "                err_list.append(c) # Compile error list of failed calibrations\n",
    "        write_log(f\"Calibration complete! Error list is:\\n{err_list}\", logfile)\n",
    "    \n",
    "    # If calibration not needed, default to using country list from data as c_list\n",
    "    else:\n",
    "        write_log(\"Hang on to outdated imperialist dogma! Using previous output...\", logfile)\n",
    "        c_list = countrylist\n",
    "        err_list = []\n",
    "\n",
    "    write_log(\"Processing results!\", logfile)\n",
    "    \n",
    "    # Initialise containers for processed country results and death data\n",
    "    res_list = []\n",
    "    dat_list = []\n",
    "    \n",
    "    # Loop through country MCMC outputs, calling master results processing function on each\n",
    "    for c in c_list:\n",
    "        try:\n",
    "            c_res, datdf = process_results(f'./{c}/{baserunname}_{c}_MC', eqtime, earlytime, \n",
    "                                           gof_vars, iqr_list, means_list, perc_list, delta, dur)\n",
    "            res_list.append(c_res)\n",
    "            dat_list.append(datdf)\n",
    "        except FileNotFoundError:\n",
    "            err_list.append(c)\n",
    "            \n",
    "    # Compile main results dataframe with processed country results\n",
    "    results = pd.concat(res_list, axis=1)\n",
    "    \n",
    "    # Compile country infection and death outputs over time\n",
    "    dpm_data, eq_death, inf_data, inf_exp = [\n",
    "        pd.concat([df.loc[var] for df in dat_list], axis=1) for var in [\n",
    "            'DeathsOverTimeRaw', 'eqDeath', 'DataFlowOverTime', 'inf exp']]\n",
    "    \n",
    "    # Assign results dataframe indices based on c_list\n",
    "    for df in [results, dpm_data, eq_death, inf_data, inf_exp]:\n",
    "        df.columns = [c for c in c_list if c not in err_list]\n",
    "    results, dpm_data, eq_death, inf_data, inf_exp = [\n",
    "        df.T for df in [results, dpm_data, eq_death, inf_data, inf_exp]]\n",
    "\n",
    "    # Recompile results dataframe with aggregate data previously separated\n",
    "    results['mean_dpm'], results['population'], results['gdp_per_cap'] = mean_dpm, popn, gdppc\n",
    "    \n",
    "    # Calculate normalised interquartile ranges (NIQRs)\n",
    "    for var in ['eq_gdn', 'eq_dpm', 'end_gdn', 'end_dpm']:\n",
    "        results[f'{var}_niqr'] = abs(results[f'{var}_0.75'] - results[f'{var}_0.25'])/results[var]\n",
    "    \n",
    "    display(results)\n",
    "    \n",
    "    # Compile infection outputs into multiindex dataframe for later graphing\n",
    "    inf_results = pd.concat([inf_data, inf_exp], keys=['inf_data', 'inf_exp'])\n",
    "    inf_results.index.names = ['field', 'iso_code']\n",
    "    \n",
    "    display(inf_results)\n",
    "    \n",
    "    # Compile death outputs into multiindex dataframe and run death regressions\n",
    "    dth_results = pd.concat([dpm_data, eq_death], keys=['dpm', 'eqDeath'])\n",
    "    dth_results.index.names = ['field', 'iso_code']\n",
    "    \n",
    "    display(dth_results)\n",
    "    \n",
    "    regdf = regress_deaths(dth_results)\n",
    "    display(regdf)\n",
    "    \n",
    "    # Generate main output tab files and copy to root directory for easy access\n",
    "    results.to_csv(f'./{baserunname}_results.tab', sep='\\t')\n",
    "    dth_results.to_csv(f'./{baserunname}_deaths.tab', sep='\\t')\n",
    "    inf_results.to_csv(f'./{baserunname}_infections.tab', sep='\\t')\n",
    "    \n",
    "    copy(f'./{baserunname}_results.tab', '../')\n",
    "    copy(f'./{baserunname}_deaths.tab', '../')\n",
    "    copy(f'./{baserunname}_infections.tab', '../')\n",
    "    copy(f'./{baserunname}_regression.tab', '../')\n",
    "    \n",
    "    os.chdir(\"..\") # Remember to go back to root directory before next iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNBR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./NBR.cin'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### SENSITIVITY ANALYSIS CODE FOR NBR TEST #####\n",
    "\n",
    "# Prepare files for NBR (no behavioural response) sensitivity run\n",
    "cf['baserunname'] = f'{basename}NBR'\n",
    "baserunname = cf['baserunname']\n",
    "print(baserunname)\n",
    "\n",
    "# Copy in necessary voc and cin files to override normal parameters\n",
    "vocname = cf['simsettings']['optparm'][:-4] + '_NBR.voc'\n",
    "cf['simsettings']['optparm'] = vocname\n",
    "cf['simsettings']['changes'].append('NBR.cin')\n",
    "copy(f\"../{vocname}\", \"./\")\n",
    "copy(f\"../NBR.cin\", \"./\")\n",
    "\n",
    "for i in [main_dur]:\n",
    "    # Create script object to cleanly create NBR subfolder\n",
    "    sub = Script(cf)\n",
    "    sub.changes.extend(scenariolist)\n",
    "    sub.copy_model_files(baserunname)\n",
    "    copy(f\"../{controlfilename}\", \"./\")\n",
    "\n",
    "    # Overwrite disease duration cin file - IMPORTANT! USES LAST FILE IN CHANGES LIST\n",
    "    with open('DiseaseDuration.cin', 'w') as f:\n",
    "        f.write(f\"DiseaseDuration = {i}\")\n",
    "\n",
    "    dur = i # Assign disease duration variable\n",
    "\n",
    "    # Initialise necessary .mdl and .voc files\n",
    "    create_mdls(cf, countrylist, finaltime, logfile)\n",
    "\n",
    "    # Run country-by-country calibration process, unless otherwise specified (mccores=0)\n",
    "    if mccores != 0:\n",
    "        write_log(f\"Initialising MCMC with duration {dur}!\", logfile)\n",
    "        c_list = []\n",
    "        err_list = []\n",
    "        for c in countrylist:\n",
    "            # First run Powell optimization, then MCMC, checking for success each time\n",
    "            res_i = compile_script(cf, CtyScript, c, 'i', {'model': f'_{c}', 'optparm': '_c'}, \n",
    "                                   logfile, subdir=c)\n",
    "            if res_i != False:\n",
    "                res = compile_script(cf, CtyMCScript, c, 'MC', {\n",
    "                    'model': f'_{c}', 'optparm': '_cmc'}, logfile, chglist=[(c, 'i')], subdir=c)\n",
    "                if res != False:\n",
    "                    c_list.append(c) # Compile updated c_list of successful calibrations\n",
    "                else:\n",
    "                    err_list.append(c) # Compile error list of failed calibrations\n",
    "            else:\n",
    "                err_list.append(c) # Compile error list of failed calibrations\n",
    "        write_log(f\"Calibration complete! Error list is:\\n{err_list}\", logfile)\n",
    "\n",
    "    # If calibration not needed, default to using country list from data as c_list\n",
    "    else:\n",
    "        write_log(\"Hang on to outdated imperialist dogma! Using previous output...\", logfile)\n",
    "        c_list = countrylist\n",
    "        err_list = []\n",
    "\n",
    "    write_log(\"Processing results!\", logfile)\n",
    "\n",
    "    # Initialise containers for processed country results and death data\n",
    "    res_list = []\n",
    "    dat_list = []\n",
    "\n",
    "    # Loop through country MCMC outputs, pulling time series results & GOF measures from each\n",
    "    for c in c_list:\n",
    "        try:\n",
    "            resdf = pd.read_csv(f'./{c}/{baserunname}_{c}_MC.tab', sep='\\t', \n",
    "                                index_col=0, error_bad_lines=False)\n",
    "            resdf.index = [n.split('[')[0] for n in resdf.index] # Separate subscripts\n",
    "            datdf = resdf.loc[['DataFlowOverTime', 'inf exp']]\n",
    "            \n",
    "            c_res = pd.Series()\n",
    "            c_res['maeom'], c_res['mape'], c_res['r2'] = calc_gof(resdf, gof_vars[0], gof_vars[1])\n",
    "            \n",
    "            res_list.append(c_res)\n",
    "            dat_list.append(datdf)\n",
    "        except FileNotFoundError:\n",
    "            err_list.append(c)\n",
    "\n",
    "    # Compile main results dataframe with country GOF measures\n",
    "    results = pd.concat(res_list, axis=1)\n",
    "\n",
    "    # Compile country infection outputs over time\n",
    "    inf_data = pd.concat([df.loc['DataFlowOverTime'] for df in dat_list], axis=1)\n",
    "    inf_exp = pd.concat([df.loc['inf exp'] for df in dat_list], axis=1)\n",
    "\n",
    "    # Assign results dataframe indices based on c_list\n",
    "    for df in [results, inf_data, inf_exp]:\n",
    "        df.columns = [c for c in c_list if c not in err_list]\n",
    "    results, inf_data, inf_exp = [df.T for df in [results, inf_data, inf_exp]]\n",
    "\n",
    "    display(results)\n",
    "\n",
    "    # Compile infection outputs into multiindex dataframe for later graphing\n",
    "    inf_results = pd.concat([inf_data, inf_exp], keys=['inf_data', 'inf_exp'])\n",
    "    inf_results.index.names = ['field', 'iso_code']\n",
    "\n",
    "    display(inf_results)\n",
    "\n",
    "    # Generate main output tab files and copy to root directory for easy access\n",
    "    results.to_csv(f'./{baserunname}_results.tab', sep='\\t')\n",
    "    inf_results.to_csv(f'./{baserunname}_infections.tab', sep='\\t')\n",
    "\n",
    "    copy(f'./{baserunname}_results.tab', '../')\n",
    "    copy(f'./{baserunname}_infections.tab', '../')\n",
    "\n",
    "    os.chdir(\"..\") # Remember to go back to root directory before next iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising <__main__.Script object at 0x0000021E4E8C2E50>\n",
      "S10\n",
      "Initialising <__main__.ScenRunScript object at 0x0000021E4E8B3100>\n",
      "Initialising S10_sens_base!\n",
      "Return code is 3221226525\n",
      "Vensim! Trying again...\n",
      "Initialising <__main__.MultiScript object at 0x0000021E4E8D53A0>\n",
      "Initialising S10_sens_beta!\n",
      "Initialising <__main__.MultiScript object at 0x0000021E4EB93370>\n",
      "Initialising S10_sens_alpha!\n",
      "Initialising <__main__.MultiScript object at 0x0000021E6D054340>\n",
      "Initialising S10_sens_PMean!\n"
     ]
    }
   ],
   "source": [
    "##### PARAMETER SENSITIVITY ANALYSIS WITH ILLUSTRATIVE MODEL #####\n",
    "\n",
    "# Prepare files for parameter sensitivity run, copying in necessary .mdl\n",
    "copy('../SensitivitySIR.mdl', './')\n",
    "smcf = cf.copy()\n",
    "smcf['simsettings']['model'] = 'SensitivitySIR.mdl'\n",
    "smcf['simsettings']['savelist'] = smcf['simsettings']['senssavelist']\n",
    "smcf['simsettings']['changes'] = ['DiseaseDuration.cin', 'BaseValues.cin']\n",
    "\n",
    "# Create script object to cleanly create Sensitivity subfolder\n",
    "sub = Script(smcf)\n",
    "sub.copy_model_files('Sensitivity')\n",
    "copy(f\"../{controlfilename}\", \"./\")\n",
    "\n",
    "for i in [maindur]:\n",
    "    smcf['baserunname'] = f'{basename}{i}'\n",
    "    baserunname = smcf['baserunname']\n",
    "    print(baserunname)\n",
    "    \n",
    "    # Overwrite disease duration cin file\n",
    "    with open('DiseaseDuration.cin', 'w') as f:\n",
    "        f.write(f\"DiseaseDuration = {i}\")\n",
    "        \n",
    "    # Read base values from cin file to use to compile setvals list\n",
    "    with open('BaseValues.cin', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        keys = [line.split('=')[0].strip() for line in lines]\n",
    "        vals = [float(line.split('=')[1]) for line in lines]\n",
    "        vals_dict = dict(zip(keys, vals))\n",
    "    \n",
    "    # Compile setvals list for sensitivity runs\n",
    "    sens_list = compile_senslist(sens_vars, vals_dict, sens_mults)\n",
    "\n",
    "    # Extend time horizon and run base case\n",
    "    with open('ExtTime.cin', 'w') as f:\n",
    "        f.write(\"FINAL TIME = 730\")\n",
    "    compile_script(smcf, ScenRunScript, 'sens', 'base', {}, logfile, chglist=['ExtTime.cin'])\n",
    "\n",
    "    # Initialise containers for Re and DPM results\n",
    "    redf_list = []\n",
    "    dthdf_list = []\n",
    "    \n",
    "    # Loop through setvals list, running each parameter's setval scenarios\n",
    "    for setvals in sens_list:\n",
    "        try:\n",
    "            os.remove(f'{baserunname}_sens_{setvals[0][0][0]}.tab') # Clear existing tab files\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        # Run MultiScript sensitivity scenarios and extract Re and DPM results for graphing\n",
    "        compile_script(smcf, MultiScript, 'sens', setvals[0][0][0], {}, logfile, setvals=setvals)\n",
    "        df = pd.read_csv(f'{baserunname}_sens_{setvals[0][0][0]}.tab', sep='\\t', index_col=[0,1])\n",
    "        redf, dthdf = df.loc['Re'], df.loc['Deaths']\n",
    "        redf_list.append(redf)\n",
    "        dthdf_list.append(dthdf)\n",
    "\n",
    "    # Compile and export Re and DPM results, clearing any duplicates from incomplete runs\n",
    "    redf = pd.concat(redf_list)\n",
    "    redf = redf[~redf.index.duplicated(keep='first')]\n",
    "    redf.to_csv(f'{baserunname}_sens_Re.tab', sep='\\t')\n",
    "    \n",
    "    dthdf = pd.concat(dthdf_list)\n",
    "    dthdf = dthdf[~dthdf.index.duplicated(keep='first')]\n",
    "    dthdf.to_csv(f'{baserunname}_sens_Death.tab', sep='\\t')\n",
    "    \n",
    "    # Copy outputs to root directory for easy access\n",
    "    copy(f'./{baserunname}_sens_base.tab', '../')\n",
    "    copy(f'./{baserunname}_sens_Re.tab', '../')\n",
    "    copy(f'./{baserunname}_sens_Death.tab', '../')\n",
    "    \n",
    "    os.chdir(\"..\") # Remember to go back to root directory before next iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "000000000000000000000000000000000000000000000000000000000000000000000000\n",
    "000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
